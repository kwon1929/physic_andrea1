"""
Physical AI ì‹œê°í™” ë°ëª¨
ë¡œë´‡ì´ ë™ì‘í•˜ëŠ” ê±¸ ëˆˆìœ¼ë¡œ ë³¼ ìˆ˜ ìˆëŠ” ë°ëª¨
"""

import os
from dotenv import load_dotenv
from src.brain.robot_brain import RobotBrain
from src.perception.speech_recognizer import VoiceCommandListener
from src.simulation.simple_robot_sim import SimpleRobotSimulator
from src.motion.action_executor import ActionExecutor
from src.simulation.visualizer import RobotVisualizer
import time

load_dotenv()


def main():
    """ì‹œê°í™” ë°ëª¨"""
    print("=" * 60)
    print("ğŸ¬ Physical AI - ì‹œê°í™” ë°ëª¨")
    print("=" * 60)

    # API í‚¤ í™•ì¸
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âœ— OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return 1

    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    print("\nì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
    brain = RobotBrain(api_key=api_key, model="gpt-4o-mini")
    listener = VoiceCommandListener(api_key=api_key)
    simulator = SimpleRobotSimulator()
    executor = ActionExecutor(simulator)

    # ì‹œê°í™” ì´ˆê¸°í™”
    print("ì‹œê°í™” ì°½ ì—´ê¸°...")
    visualizer = RobotVisualizer(interactive=True)

    print("âœ… ì´ˆê¸°í™” ì™„ë£Œ\n")

    # ì´ˆê¸° ìƒíƒœ í‘œì‹œ
    print("ì´ˆê¸° ìƒíƒœ í‘œì‹œ ì¤‘...")
    visualizer.draw_state(simulator, title="ì´ˆê¸° ìƒíƒœ")
    time.sleep(2)

    # ë°ëª¨ ì‹œë‚˜ë¦¬ì˜¤
    scenarios = [
        {
            "file": "test_audio/command1.wav",
            "description": "ë¹¨ê°„ ë¸”ë¡ ì§‘ê¸°"
        },
        {
            "file": "test_audio/command2.wav",
            "description": "ì´ˆê¸° ìœ„ì¹˜ë¡œ ë³µê·€"
        },
    ]

    for i, scenario in enumerate(scenarios, 1):
        audio_file = scenario["file"]
        description = scenario["description"]

        print("\n" + "=" * 60)
        print(f"ì‹œë‚˜ë¦¬ì˜¤ {i}/{len(scenarios)}: {description}")
        print("=" * 60)

        if not os.path.exists(audio_file):
            print(f"âœ— íŒŒì¼ ì—†ìŒ: {audio_file}")
            continue

        # 1. ìŒì„± ì¸ì‹
        print("\n[1ë‹¨ê³„] ìŒì„± ì¸ì‹")
        user_speech = listener.listen_from_file(audio_file)

        # 2. AI ë‘ë‡Œ
        print("\n[2ë‹¨ê³„] AI ì‚¬ê³  ë° ê³„íš")
        print("ğŸ§  ë¡œë´‡ì´ ìƒê° ì¤‘...")
        response = brain.think(user_speech)
        print(f"\nğŸ’¬ ë¡œë´‡: {response.speech}")

        # 3. ë™ì‘ ì‹¤í–‰ (ì‹œê°í™” í¬í•¨)
        if response.commands:
            print("\n[3ë‹¨ê³„] ë™ì‘ ì‹¤í–‰")
            print(f"âš™ï¸  {len(response.commands)}ê°œ ë™ì‘ ì‹¤í–‰ ì‹œì‘")

            for j, command in enumerate(response.commands, 1):
                print(f"\n[ë™ì‘ {j}/{len(response.commands)}]")
                print(f"âš™ï¸  ì‹¤í–‰: {command.action_type}", end="")
                if command.target_object:
                    print(f" (ëŒ€ìƒ: {command.target_object})", end="")
                print(f" - {command.reasoning}")

                # ë™ì‘ ì „ ìƒíƒœ
                visualizer.draw_state(simulator, title=f"ë™ì‘ {j} ì‹¤í–‰ ì „")

                # ë™ì‘ ì‹¤í–‰
                executor.execute_command(command)

                # ë™ì‘ í›„ ìƒíƒœ
                visualizer.draw_state(simulator, title=f"ë™ì‘ {j} ì™„ë£Œ")
                time.sleep(1)

        else:
            print("\n(ëŒ€í™”ë§Œ í•˜ê³  ë™ì‘ì€ ì—†ìŠµë‹ˆë‹¤)")

        # ìµœì¢… ìƒíƒœ
        print("\n" + "=" * 60)
        print("ìµœì¢… ìƒíƒœ:")
        print(simulator.get_state_summary())
        visualizer.draw_state(simulator, title=f"ì‹œë‚˜ë¦¬ì˜¤ {i} ì™„ë£Œ")

        if i < len(scenarios):
            print("\n[ë‹¤ìŒ ì‹œë‚˜ë¦¬ì˜¤ë¡œ ê³„ì†...]")
            time.sleep(3)

    # ì™„ë£Œ
    print("\n" + "=" * 60)
    print("âœ… ë°ëª¨ ì™„ë£Œ!")
    print("=" * 60)
    print("\nì‹œê°í™” ì°½ì´ ì—´ë ¤ìˆìŠµë‹ˆë‹¤.")
    print("ì°½ì„ ë‹«ìœ¼ë ¤ë©´ ì•„ë¬´ í‚¤ë‚˜ ëˆ„ë¥´ì„¸ìš”...")

    input()
    visualizer.close()

    return 0


if __name__ == "__main__":
    import sys
    sys.exit(main())
